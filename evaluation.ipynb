{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evals\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import IJB_evals\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv_attention_models\n",
    "import GhostFaceNets, GhostFaceNets_with_Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways to load the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4060 Ti, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# #Either\n",
    "# basic_model = keras.models.load_model('checkpoints/ghostnetv1_w1.3_s2.h5', compile=False)\n",
    "\n",
    "basic_model = keras.models.load_model('D:/CODE/PYTHON/Do_an/v2/GhostFaceNets/checkpoints/ghostnetv1_w1.3_s2_new_data_(8file_githud)_basic_agedb_30_epoch_1_0.560333.h5', compile=False)\n",
    "\n",
    "\n",
    "# basic_model = keras.models.load_model('checkpoints/ghostnetv1_w1.3_s1_basic_agedb_30_epoch_2_0.863500.h5.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the above did not work, then you need to build the model then load the weights. e.g.,\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model, target_activation='PReLU')\n",
    "\n",
    "basic_model.load_weights('checkpoints/ghostnetv1_w1.3_s2.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either\n",
    "basic_model = keras.models.load_model('D:/CODE/PYTHON/Do_an/v2/GhostFaceNets/checkpoints/ghostnetv1_w1.3_s2_new_data_(8file_githud)_basic_agedb_30_epoch_1_0.560333.h5', compile=False)\n",
    "#Either\n",
    "# basic_model = keras.models.load_model('checkpoints/ghostnetv1_w1.3_s1.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation --> activation\n",
      ">>>> Convert ReLU: activation_1 --> activation_1\n",
      ">>>> Convert ReLU: activation_2 --> activation_2\n",
      ">>>> Convert ReLU: activation_3 --> activation_3\n",
      ">>>> Convert ReLU: activation_4 --> activation_4\n",
      ">>>> Convert ReLU: activation_5 --> activation_5\n",
      ">>>> Convert ReLU: activation_6 --> activation_6\n",
      ">>>> Convert ReLU: activation_7 --> activation_7\n",
      ">>>> Convert ReLU: activation_8 --> activation_8\n",
      ">>>> Convert ReLU: activation_9 --> activation_9\n",
      ">>>> Convert ReLU: activation_11 --> activation_11\n",
      ">>>> Convert ReLU: activation_12 --> activation_12\n",
      ">>>> Convert ReLU: activation_13 --> activation_13\n",
      ">>>> Convert ReLU: activation_15 --> activation_15\n",
      ">>>> Convert ReLU: activation_16 --> activation_16\n",
      ">>>> Convert ReLU: activation_17 --> activation_17\n",
      ">>>> Convert ReLU: activation_18 --> activation_18\n",
      ">>>> Convert ReLU: activation_19 --> activation_19\n",
      ">>>> Convert ReLU: activation_20 --> activation_20\n",
      ">>>> Convert ReLU: activation_21 --> activation_21\n",
      ">>>> Convert ReLU: activation_22 --> activation_22\n",
      ">>>> Convert ReLU: activation_23 --> activation_23\n",
      ">>>> Convert ReLU: activation_24 --> activation_24\n",
      ">>>> Convert ReLU: activation_25 --> activation_25\n",
      ">>>> Convert ReLU: activation_27 --> activation_27\n",
      ">>>> Convert ReLU: activation_28 --> activation_28\n",
      ">>>> Convert ReLU: activation_29 --> activation_29\n",
      ">>>> Convert ReLU: activation_31 --> activation_31\n",
      ">>>> Convert ReLU: activation_32 --> activation_32\n",
      ">>>> Convert ReLU: activation_33 --> activation_33\n",
      ">>>> Convert ReLU: activation_35 --> activation_35\n",
      ">>>> Convert ReLU: activation_36 --> activation_36\n",
      ">>>> Convert ReLU: activation_37 --> activation_37\n",
      ">>>> Convert ReLU: activation_38 --> activation_38\n",
      ">>>> Convert ReLU: activation_39 --> activation_39\n",
      ">>>> Convert ReLU: activation_41 --> activation_41\n",
      ">>>> Convert ReLU: activation_42 --> activation_42\n",
      ">>>> Convert ReLU: activation_43 --> activation_43\n",
      ">>>> Convert ReLU: activation_44 --> activation_44\n",
      ">>>> Convert ReLU: activation_45 --> activation_45\n",
      ">>>> Convert ReLU: activation_47 --> activation_47\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' conv2d/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 20), and the assigned value shape (16, 3, 3, 3) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39madd_l2_regularizer_2_model(basic_model, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, apply_to_batch_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39mreplace_ReLU_with_PReLU(basic_model, target_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPReLU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mbasic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/CODE/PYTHON/Do_an/v2/GhostFaceNets/checkpoints/ghostnetv1_w1.3_s2_new_data_(8file_githud)_basic_agedb_30_epoch_1_0.560333.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py:3930\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m   3929\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[1;32m-> 3930\u001b[0m     \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3932\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m get_graph()\u001b[38;5;241m.\u001b[39mas_default():\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot assign value to variable ' conv2d/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 20), and the assigned value shape (16, 3, 3, 3) are incompatible."
     ]
    }
   ],
   "source": [
    "#If the above did not work, then you need to build the model then load the weights. e.g.,\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model, target_activation='PReLU')\n",
    "\n",
    "basic_model.load_weights('D:/CODE/PYTHON/Do_an/v2/GhostFaceNets/checkpoints/ghostnetv1_w1.3_s2_new_data_(8file_githud)_basic_agedb_30_epoch_1_0.560333.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating lfw: 100%|██████████| 47/47 [00:39<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> lfw evaluation max accuracy: 0.996833, thresh: 0.223459, previous max accuracy: 0.000000, PCA accuray = 0.996000 ± 0.002494\n",
      ">>>> Improved = 0.996833\n"
     ]
    }
   ],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/lfw.bin', batch_size=256, flip=True, PCA_acc=True)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/lfw.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/vgg2_fp.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/cfp_ff.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/cfp_fp.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/calfw.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/cplfw.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = evals.eval_callback(basic_model, 'datasets/faces_emore/agedb_30.bin', batch_size=256, flip=True, PCA_acc=False)\n",
    "ee.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = IJB_evals.IJB_test(lambda imgs: basic_model((tf.cast(imgs, \"float32\") - 127.5) * 0.0078125).numpy(), data_path='path_to_IJB_Dataset/ijb-testsuite/ijb', subset='IJBB', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tt.run_model_test_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IJB_evals.plot_roc_and_calculate_tpr([score], names=[basic_model.name + \"_IJBB\"], label=tt.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = IJB_evals.IJB_test(lambda imgs: basic_model((tf.cast(imgs, \"float32\") - 127.5) * 0.0078125).numpy(), data_path='C:/Users/mohda/Downloads/ijb-testsuite/ijb', subset='IJBC', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tt.run_model_test_single()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IJB_evals.plot_roc_and_calculate_tpr([score], names=[basic_model.name + \"_IJBC\"], label=tt.label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot face quality distribution using norm value of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = tf.norm(ee.embs, axis=1).numpy()\n",
    "_ = plt.hist(cc, bins=512, alpha=0.5, label='agedb_30 quality')\n",
    "cc = tf.norm(tt.embs, axis=1).numpy()\n",
    "_ = plt.hist(cc, bins=512, alpha=0.5, label='IJBC quality')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall tensorflow keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow keras keras-cv-attention-models glob2 pandas tqdm scikit-learn scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.7.0 keras==2.7 keras-cv-attention-models glob2 pandas tqdm scikit-learn scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-cv-attention-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import losses, train, GhostFaceNets\n",
    "import tensorflow as tf\n",
    "import keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4060 Ti, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# Remove the below for better accuracies and keep it for faster training\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "# data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "# data_path = data_basic_path + '_112x112_folders'\n",
    "# eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/data_0_200_112x112_folders'\n",
    "eval_paths = ['datasets/data_0_200/lfw.bin', 'datasets/data_0_200/cfp_fp.bin', 'datasets/data_0_200/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: activation --> activation\n",
      ">>>> Convert ReLU: activation_1 --> activation_1\n",
      ">>>> Convert ReLU: activation_2 --> activation_2\n",
      ">>>> Convert ReLU: activation_3 --> activation_3\n",
      ">>>> Convert ReLU: activation_4 --> activation_4\n",
      ">>>> Convert ReLU: activation_5 --> activation_5\n",
      ">>>> Convert ReLU: activation_6 --> activation_6\n",
      ">>>> Convert ReLU: activation_7 --> activation_7\n",
      ">>>> Convert ReLU: activation_8 --> activation_8\n",
      ">>>> Convert ReLU: activation_9 --> activation_9\n",
      ">>>> Convert ReLU: activation_11 --> activation_11\n",
      ">>>> Convert ReLU: activation_12 --> activation_12\n",
      ">>>> Convert ReLU: activation_13 --> activation_13\n",
      ">>>> Convert ReLU: activation_15 --> activation_15\n",
      ">>>> Convert ReLU: activation_16 --> activation_16\n",
      ">>>> Convert ReLU: activation_17 --> activation_17\n",
      ">>>> Convert ReLU: activation_18 --> activation_18\n",
      ">>>> Convert ReLU: activation_19 --> activation_19\n",
      ">>>> Convert ReLU: activation_20 --> activation_20\n",
      ">>>> Convert ReLU: activation_21 --> activation_21\n",
      ">>>> Convert ReLU: activation_22 --> activation_22\n",
      ">>>> Convert ReLU: activation_23 --> activation_23\n",
      ">>>> Convert ReLU: activation_24 --> activation_24\n",
      ">>>> Convert ReLU: activation_25 --> activation_25\n",
      ">>>> Convert ReLU: activation_27 --> activation_27\n",
      ">>>> Convert ReLU: activation_28 --> activation_28\n",
      ">>>> Convert ReLU: activation_29 --> activation_29\n",
      ">>>> Convert ReLU: activation_31 --> activation_31\n",
      ">>>> Convert ReLU: activation_32 --> activation_32\n",
      ">>>> Convert ReLU: activation_33 --> activation_33\n",
      ">>>> Convert ReLU: activation_35 --> activation_35\n",
      ">>>> Convert ReLU: activation_36 --> activation_36\n",
      ">>>> Convert ReLU: activation_37 --> activation_37\n",
      ">>>> Convert ReLU: activation_38 --> activation_38\n",
      ">>>> Convert ReLU: activation_39 --> activation_39\n",
      ">>>> Convert ReLU: activation_41 --> activation_41\n",
      ">>>> Convert ReLU: activation_42 --> activation_42\n",
      ">>>> Convert ReLU: activation_43 --> activation_43\n",
      ">>>> Convert ReLU: activation_44 --> activation_44\n",
      ">>>> Convert ReLU: activation_45 --> activation_45\n",
      ">>>> Convert ReLU: activation_47 --> activation_47\n"
     ]
    }
   ],
   "source": [
    "#GhostFaceNetV1\n",
    "# # Strides of 2\n",
    "# basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "# basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "# basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> L2 regularizer value from basic_model: 0.00025\n"
     ]
    }
   ],
   "source": [
    "# # Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2_new_data_0_200.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# # Strides of 1\n",
    "# tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "#     save_path='ghostnetv1_w1.3_s1_new_data_0_200.h5',\n",
    "#     basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "#     batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add_emb_output_to_model__', '__basic_train__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_dataset__', '__init_emb_losses__', '__init_model__', '__init_optimizer__', '__init_subclass__', '__init_type_by_loss__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__search_embedding_layer__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'arcface', 'arcface_partial', 'basic_model', 'batch_size', 'batch_size_per_replica', 'center', 'classes', 'custom_callbacks', 'data_path', 'default_optimizer', 'distill', 'distill_emb_map_layer', 'gently_stop', 'image_per_class', 'inited_from_model', 'is_distill_ds', 'is_triplet_dataset', 'lr_scheduler', 'metrics', 'mixup_alpha', 'model', 'model_checkpoint', 'my_evals', 'my_history', 'output_weight_decay', 'partial_fc_split', 'pretrained', 'random_cutout_mask_area', 'random_status', 'reset_dataset', 'sam_rho', 'samples_per_mining', 'save_path', 'softmax', 'steps_per_epoch', 'teacher_model_interf', 'train', 'train_ds', 'train_single_scheduler', 'triplet', 'vpl_allowed_delta', 'vpl_start_iters']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tt))  # Kiểm tra xem 'train' có nằm trong danh sách không\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Init type by loss function name...\n",
      ">>>> Train arcface...\n",
      ">>>> Init softmax dataset...\n",
      ">>>> reloaded from dataset backup: data_0_200_112x112_folders_shuffle.npz\n",
      ">>>> Image length: 14472, Image class length: 14472, classes: 201\n",
      ">>>> Use specified optimizer: <keras.optimizer_v2.gradient_descent.SGD object at 0x000001D2CEFBAEE0>\n",
      ">>>> Add L2 regularizer to model output layer, output_weight_decay = 0.000500\n",
      ">>>> Add arcface layer, arc_kwargs={'loss_top_k': 1, 'append_norm': False, 'partial_fc_split': 0, 'name': 'arcface'}, vpl_kwargs={'vpl_lambda': 0.15, 'start_iters': -113, 'allowed_delta': 200}...\n",
      ">>>> loss_weights: {'arcface': 1}\n",
      "\n",
      "Learning rate for iter 1 is 0.10000000149011612, global_iterNum is 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m sch \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: losses\u001b[38;5;241m.\u001b[39mArcfaceLoss(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer},\n\u001b[0;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: losses\u001b[38;5;241m.\u001b[39mArcfaceLoss(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m},\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# tt.steps_per_epoch = 10\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODE\\PYTHON\\Do_an\\v2\\GhostFaceNets\\train.py:524\u001b[0m, in \u001b[0;36mTrain.train\u001b[1;34m(self, train_schedule, initial_epoch)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sch:\n\u001b[0;32m    522\u001b[0m     sch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtripletAlpha\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 524\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_single_scheduler(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msch, initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch)\n\u001b[0;32m    525\u001b[0m initial_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbottleneckOnly\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m sch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstop_training \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32md:\\CODE\\PYTHON\\Do_an\\v2\\GhostFaceNets\\train.py:505\u001b[0m, in \u001b[0;36mTrain.train_single_scheduler\u001b[1;34m(self, epoch, loss, initial_epoch, lossWeight, optimizer, bottleneckOnly, lossTopK, type, embLossTypes, embLossWeights, tripletAlpha)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__basic_train__\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> Train \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m DONE!!! epochs = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, model.stop_training = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mepoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstop_training))\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> My history:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\CODE\\PYTHON\\Do_an\\v2\\GhostFaceNets\\train.py:396\u001b[0m, in \u001b[0;36mTrain.__basic_train__\u001b[1;34m(self, epochs, initial_epoch)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__basic_train__\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs, initial_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_loss, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, loss_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weights)\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# steps_per_epoch=0,\u001b[39;49;00m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:975\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    972\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    978\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    979\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "# tt.steps_per_epoch = 10\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.1\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(h5py.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Create a checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='D:/CODE/PYTHON/Do_an/code_anh_tien/GhostFaceNets/checkpointsbest_model.h5',  # Specify the path where the best model should be saved\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    save_best_only=True,  # Save only when the monitored metric improves\n",
    "    mode='min'  # The mode can be 'min', 'max', or 'auto'\n",
    ")\n",
    "\n",
    "# Add this callback to the list of callbacks in the Train class\n",
    "tt.callbacks.append(checkpoint_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "3.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import h5py\n",
    "print(h5py.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Specify the desired file path with .h5 extension\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtt\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave(model_save_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "model_save_path = 'your_model.h5'  # Specify the desired file path with .h5 extension\n",
    "tt.model.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from tensorflow import keras\n",
    "\n",
    "# def save_model(model, save_path):\n",
    "#     if model is None:\n",
    "#         print(\">>>> Error: Model is not initialized.\")\n",
    "#         return\n",
    "    \n",
    "#     # Save the model to the specified path\n",
    "#     try:\n",
    "#         model.save(save_path)\n",
    "#         print(f\">>>> Model saved successfully to {save_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\">>>> Error in saving model: {str(e)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example load and save\n",
    "#     try:\n",
    "#         # Assuming the model is loaded from the checkpoint\n",
    "#         model = keras.models.load_model(\"your_model_checkpoint.h5\")\n",
    "#         save_model(model, \"new_saved_model.h5\")\n",
    "#     except Exception as e:\n",
    "#         print(f\">>>> Error in loading or saving model: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "def save_basic_model(basic_model, save_path):\n",
    "    latest_save_path = os.path.join(\"checkpoints\", os.path.splitext(save_path)[0] + \"_basic_model_latest.h5\")\n",
    "    print(\">>>> Saving latest basic model to:\", latest_save_path)\n",
    "    basic_model.save(latest_save_path)\n",
    "    print(\">>>> Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install h5py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "# data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "# data_path = data_basic_path + '_112x112_folders'\n",
    "# eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n",
      ">>>> Convert ReLU: stack4_se_relu --> stack4_se_prelu\n",
      ">>>> Convert ReLU: stack5_se_relu --> stack5_se_prelu\n",
      ">>>> Convert ReLU: stack10_se_relu --> stack10_se_prelu\n",
      ">>>> Convert ReLU: stack11_se_relu --> stack11_se_prelu\n",
      ">>>> Convert ReLU: stack12_se_relu --> stack12_se_prelu\n",
      ">>>> Convert ReLU: stack14_se_relu --> stack14_se_prelu\n",
      ">>>> Convert ReLU: stack16_se_relu --> stack16_se_prelu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "backbones.ghostv2.GhostNetV2() got multiple values for keyword argument 'stem_strides'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets\u001b[38;5;241m.\u001b[39mreplace_ReLU_with_PReLU(basic_model)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Strides of 1\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m \u001b[43mGhostFaceNets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuildin_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mghostnetv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGDC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem_strides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets\u001b[38;5;241m.\u001b[39madd_l2_regularizer_2_model(basic_model, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, apply_to_batch_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets\u001b[38;5;241m.\u001b[39mreplace_ReLU_with_PReLU(basic_model)\n",
      "File \u001b[1;32md:\\CODE\\PYTHON\\Do_an\\code_anh_tien\\GhostFaceNets\\GhostFaceNets.py:52\u001b[0m, in \u001b[0;36mbuildin_models\u001b[1;34m(stem_model, dropout, emb_shape, input_shape, output_layer, bn_momentum, bn_epsilon, add_pointwise_conv, pointwise_conv_act, use_bias, scale, weights, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuildin_models\u001b[39m(\n\u001b[0;32m     37\u001b[0m     stem_model,\n\u001b[0;32m     38\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     50\u001b[0m ):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stem_model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m         xx \u001b[38;5;241m=\u001b[39m __init_model_from_name__(stem_model, input_shape, weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     53\u001b[0m         name \u001b[38;5;241m=\u001b[39m stem_model\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\CODE\\PYTHON\\Do_an\\code_anh_tien\\GhostFaceNets\\GhostFaceNets.py:17\u001b[0m, in \u001b[0;36m__init_model_from_name__\u001b[1;34m(name, input_shape, weights, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name_lower \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghostnetv2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbackbones\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ghostv2\n\u001b[1;32m---> 17\u001b[0m     xx \u001b[38;5;241m=\u001b[39m ghostv2\u001b[38;5;241m.\u001b[39mGhostNetV2(stem_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m     18\u001b[0m                             stem_strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     19\u001b[0m                             width_mul\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.3\u001b[39m,\n\u001b[0;32m     20\u001b[0m                             num_ghost_module_v1_stacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# num of `ghost_module` stcks on the head, others are `ghost_module_multiply`, set `-1` for all using `ghost_module`\u001b[39;00m\n\u001b[0;32m     21\u001b[0m                             input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m112\u001b[39m, \u001b[38;5;241m112\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m     22\u001b[0m                             num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     23\u001b[0m                             activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprelu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m                             classifier_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m                             dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     26\u001b[0m                             pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m                             model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghostnetv2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m                             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: backbones.ghostv2.GhostNetV2() got multiple values for keyword argument 'stem_strides'"
     ]
    }
   ],
   "source": [
    "# #GhostFaceNetV2\n",
    "# # Strides of 2\n",
    "# basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "# basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "# basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Strides of 2\n",
    "# tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "#     save_path='ghostnetv2_w1.3_s2.h5',\n",
    "#     basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "#     batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CosFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.CosFaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.CosFaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcenter ArcFace Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV1\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" First, Train with `lossTopK = 3` \"\"\"\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer, \"lossTopK\": 3},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50, \"lossTopK\": 3},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Then drop non-dominant subcenters and high-confident noisy data, which is `>75 degrees` \"\"\"\n",
    "import data_drop_top_k\n",
    "# data_drop_top_k.data_drop_top_k('./checkpoints/TT_mobilenet_topk_bs256.h5', '/datasets/faces_casia_112x112_folders/', limit=20)\n",
    "new_data_path = data_drop_top_k.data_drop_top_k(tt.model, tt.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train with the new dataset again, this time `lossTopK = 1` \"\"\"\n",
    "tt.reset_dataset(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can continue training the model or start training again and considering the generated dataset as a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models from scatch using the new generated dataset\n",
    "\n",
    "# New Cleaned Dataset\n",
    "data_path = 'Path_To_New_Generated_Dataset'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
